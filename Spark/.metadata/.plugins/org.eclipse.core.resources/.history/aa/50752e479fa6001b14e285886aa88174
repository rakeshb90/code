package com.demo;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.ml.classification.LogisticRegression;
import org.apache.spark.ml.classification.LogisticRegressionModel;
import org.apache.spark.ml.evaluation.RegressionEvaluator;
import org.apache.spark.ml.feature.OneHotEncoder;
import org.apache.spark.ml.feature.StringIndexer;
import org.apache.spark.ml.feature.VectorAssembler;
import org.apache.spark.ml.param.ParamMap;
import org.apache.spark.ml.tuning.ParamGridBuilder;
import org.apache.spark.ml.tuning.TrainValidationSplit;
import org.apache.spark.ml.tuning.TrainValidationSplitModel;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import static org.apache.spark.sql.functions.*;

public class LogisticModel {

	public static void main(String[] args) {
		Logger.getLogger("org.apache").setLevel(Level.WARN);
		SparkSession spark=SparkSession.builder()
				.appName("Loan Approval Prediction")
				.master("local[*]")
				.config("spark.some.config.option","some-value")
				.getOrCreate();
		Dataset<Row> csvData=spark.read()
				.option("header", true)
				.option("inferSchema", true)
				.csv("src/main/resources/input/loan_prediction.csv");
		csvData=csvData.drop("Loan_ID");
		// male=1,self_employed_Yes=1,Married_Yes=1,Education_Graduation=1
		csvData=csvData.withColumn("Gender", when(col("Gender").like("Female"),0).otherwise(1))
//				.withColumn("Self_Employed", when(col("Self_Employed").like("No"),0).otherwise(1))
//				.withColumn("Married", when(col("Married").like("No"),0).otherwise(1))
//				.withColumn("Education", when(col("Education").like("Not Graduate"),0).otherwise(1))
//				.withColumn("Dependents", when(col("Dependents").isNull(),0).otherwise(col("Dependents")))
//				.withColumn("Credit_History", when(col("Credit_History").isNull(),0).otherwise(col("Credit_History")))
//				.withColumn("Property_Area", when(col("Property_Area").like("Urban"),1).otherwise(0))
//				.withColumn("ApplicantIncome", when(col("ApplicantIncome").$greater$eq(43517),1).otherwise(0))
//				.withColumn("CoapplicantIncome", when(col("CoapplicantIncome").$greater$eq(14400),1).otherwise(0))
//		        .withColumn("LoanAmount", when(col("LoanAmount").$less$eq(150),1).otherwise(0))
//		        .withColumn("Loan_Amount_Term", when(col("Loan_Amount_Term").$greater$eq(150),1).otherwise(0));


//		csvData=csvData.withColumnRenamed("LoanAmount", "label");
		StringIndexer GenderIndex=new StringIndexer()
				.setInputCol("Gender")
				.setOutputCol("GenderIndex")
				.setHandleInvalid("skip");
		csvData=GenderIndex.fit(csvData).transform(csvData);
		
		StringIndexer Self_EmployedIndex=new StringIndexer()
				.setInputCol("Self_Employed")
				.setOutputCol("Self_EmployedIndex")
				.setHandleInvalid("skip");
		csvData=Self_EmployedIndex.fit(csvData).transform(csvData);
		
		StringIndexer MarriedIndex=new StringIndexer()
				.setInputCol("Married")
				.setOutputCol("MarriedIndex")
				.setHandleInvalid("skip");
		csvData=MarriedIndex.fit(csvData).transform(csvData);
		
		StringIndexer EducationIndex=new StringIndexer()
				.setInputCol("Education")
				.setOutputCol("EducationIndex")
				.setHandleInvalid("skip");
		csvData=EducationIndex.fit(csvData).transform(csvData);
		
		StringIndexer Property_AreaIndex=new StringIndexer()
				.setInputCol("Property_Area")
				.setOutputCol("Property_AreaIndex")
				.setHandleInvalid("skip");
		csvData=Property_AreaIndex.fit(csvData).transform(csvData);
		
		
//		OneHotEncoder encoder=new OneHotEncoder()
//				.setInputCols(new String[] {"genderIndex","Self_EmployedIndex","MarriedIndex","EducationIndex","propertyAreaIndex"})
//				.setOutputCols(new String[] {"genderVector","selfEmploedVector","marriedVector","educationVector","propertyAreaVector"});
//		csvData=encoder.fit(csvData).transform(csvData);
		csvData.show();
//		VectorAssembler assembler=new VectorAssembler()
//				.setInputCols(new String[] {"genderVector","marriedVector","Dependents","educationVector","selfEmployedVector","ApplicantIncome","CoapplicantIncome","Loan_Amount_Term","Credit_History","propertyAreaVector"})
//				.setOutputCol("features");
//		
//		Dataset<Row> modelInput=assembler.transform(csvData)
//				.select("LoanAmount","features")
//				.withColumnRenamed("LoanAmount", "label");
//			
//		Dataset<Row>[] splitData=modelInput.randomSplit(new double[] {0.8,0.2});
//		Dataset<Row> traningAndTestData=splitData[0];
//		Dataset<Row>  holdOutData=splitData[1];
//		
//		LogisticRegression logisticRegression=new LogisticRegression();
//		ParamGridBuilder gridBuilder=new ParamGridBuilder();
//		
//		ParamMap[] paramMap=gridBuilder
//				.addGrid(logisticRegression.regParam(),new double[] {0.01,0.05,0.1,0.15,0.5})
//				.addGrid(logisticRegression.elasticNetParam(),new double[] {0,0.1,0.3,0.5,1})
//				.build();
//		
//		TrainValidationSplit tvs=new TrainValidationSplit()
//				.setEstimator(logisticRegression)
//				.setEvaluator(new RegressionEvaluator().setMetricName("r2"))
//				.setEstimatorParamMaps(paramMap)
//				.setTrainRatio(0.8);
//				
//				
//		TrainValidationSplitModel model=tvs.fit(modelInput);
//		
//		LogisticRegressionModel lrModel=(LogisticRegressionModel) model.bestModel();
////		csvData.printSchema();
////		modelInput.show();
////		csvData.describe().show();
//		System.out.println("Accouracy: "+lrModel.summary().accuracy());
		spark.close();


	}

}
